{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from PIL import Image\n",
    "import pandas as pd\n",
    "import random\n",
    "import numpy as np\n",
    "import shutil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_dir = r\"C:\\Users\\fcali\\OneDrive\\Masaüstü\\DATA SCIENCE\\WEB-SCRAPING\\AMAZON\\AMAZON_DATA\\ABO_BERKELEY\\SORTED\"\n",
    "output_dir = r\"C:\\Users\\fcali\\OneDrive\\Masaüstü\\DATA SCIENCE\\WEB-SCRAPING\\AMAZON\\AMAZON_DATA\\ABO_BERKELEY\\SORTED224\"\n",
    "base_directory = r\"C:\\Users\\fcali\\OneDrive\\Masaüstü\\DATA SCIENCE\\WEB-SCRAPING\\AMAZON\\AMAZON_DATA\\PRODUCT_IMAGES\\AMAZON_IMAGES\\PROCESSED_IMAGES\\FINAL_DATASET\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rename_and_resize_images(input_dir, output_base_dir, target_size=(224, 224)):\n",
    "    for root, dirs, files in os.walk(input_dir):\n",
    "        for dir_name in dirs:\n",
    "            # Create corresponding subdirectories in the output directory\n",
    "            subdir_path = os.path.join(root, dir_name)\n",
    "            relative_path = os.path.relpath(subdir_path, input_dir)\n",
    "            output_subdir = os.path.join(output_base_dir, relative_path + '_processed')\n",
    "            \n",
    "            if not os.path.exists(output_subdir):\n",
    "                os.makedirs(output_subdir)\n",
    "\n",
    "        for file_index, file in enumerate(files):\n",
    "            file_path = os.path.join(root, file)\n",
    "            try:\n",
    "                # Load image using PIL\n",
    "                image = Image.open(file_path)\n",
    "                \n",
    "                # Resize image with padding\n",
    "                image = resize_and_pad_image(image, target_size)\n",
    "                \n",
    "                # Determine the output path and save the image with a new name\n",
    "                category = os.path.basename(root)[:4]  # Get first 3 letters of the category\n",
    "                new_name = f'{category}_{file_index}_abo.jpeg'\n",
    "                relative_path = os.path.relpath(root, input_dir)\n",
    "                output_subdir = os.path.join(output_base_dir, relative_path + '_processed')\n",
    "                output_path = os.path.join(output_subdir, new_name)\n",
    "                image.save(output_path, 'JPEG')\n",
    "            except Exception as e:\n",
    "                print(f'Error processing {file_path}: {e}')\n",
    "\n",
    "def resize_and_pad_image(image, target_size, padding_color=(255, 255, 255)):\n",
    "    # Resize image while maintaining aspect ratio\n",
    "    image.thumbnail(target_size, Image.Resampling.LANCZOS)\n",
    "    \n",
    "    # Create a new image with white background\n",
    "    new_image = Image.new('RGB', target_size, padding_color)\n",
    "    \n",
    "    # Calculate position to paste the resized image on the new image\n",
    "    left = (target_size[0] - image.size[0]) // 2\n",
    "    top = (target_size[1] - image.size[1]) // 2\n",
    "    new_image.paste(image, (left, top))\n",
    "    \n",
    "    return new_image\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Class name mapping\n",
    "class_mapping = {\n",
    "    'bab_processed': 'BABY_PRODUCTS',\n",
    "    'bea_processed': 'BEAUTY_HEALTH',\n",
    "    'clo_processed': 'CLOTHING_ACCESSORIES_JEWELLERY',\n",
    "    'ele_processed': 'ELECTRONICS',\n",
    "    'gro_processed': 'GROCERY_FOOD',\n",
    "    'hob_processed': 'HOBBY_ARTS_STATIONERY',\n",
    "    'hom_processed': 'HOME_KITCHEN_TOOLS',\n",
    "    'pet_processed': 'PET_SUPPLIES',\n",
    "    'spo_processed': 'SPORTS_OUTDOOR'\n",
    "}\n",
    "\n",
    "# Ensure output directories exist\n",
    "sub_dirs = ['train', 'val', 'check']\n",
    "for sub_dir in sub_dirs:\n",
    "    for class_name in class_mapping.values():\n",
    "        os.makedirs(os.path.join(output_directory, sub_dir, class_name), exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['bab_processed',\n",
       " 'bea_processed',\n",
       " 'clo_processed',\n",
       " 'ele_processed',\n",
       " 'gro_processed',\n",
       " 'hob_processed',\n",
       " 'hom_processed',\n",
       " 'pet_processed',\n",
       " 'spo_processed']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target_directory = r'C:\\Users\\fcali\\OneDrive\\Masaüstü\\DATA SCIENCE\\WEB-SCRAPING\\AMAZON\\AMAZON_DATA\\PRODUCT_IMAGES\\AMAZON_IMAGES\\PROCESSED_IMAGES\\FINAL_DATASET_3_SPLITTED'\n",
    "base_directory = r\"C:\\Users\\fcali\\OneDrive\\Masaüstü\\DATA SCIENCE\\WEB-SCRAPING\\AMAZON\\AMAZON_DATA\\PRODUCT_IMAGES\\AMAZON_IMAGES\\PROCESSED_IMAGES\\FINAL_DATASET\"\n",
    "\n",
    "os.listdir(base_directory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Class name mappings\n",
    "class_mapping = {\n",
    "    'bab_processed': 'BABY_PRODUCTS',\n",
    "    'bea_processed': 'BEAUTY_HEALTH',\n",
    "    'clo_processed': 'CLOTHING_ACCESSORIES_JEWELLERY',\n",
    "    'ele_processed': 'ELECTRONICS',\n",
    "    'gro_processed': 'GROCERY',\n",
    "    'hob_processed': 'HOBBY_ARTS_STATIONERY',\n",
    "    'hom_processed': 'HOME_KITCHEN_TOOLS',\n",
    "    'pet_processed': 'PET_SUPPLIES',\n",
    "    'spo_processed': 'SPORTS_OUTDOOR'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "def downsample_class(file_list, target_count):\n",
    "    return random.sample(file_list, target_count)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_dataset(file_list, train_ratio=0.77, val_ratio=0.20, check_ratio=0.03):\n",
    "    random.shuffle(file_list)\n",
    "    total_count = len(file_list)\n",
    "    train_end = int(train_ratio * total_count)\n",
    "    val_end = train_end + int(val_ratio * total_count)\n",
    "    \n",
    "    train_files = file_list[:train_end]\n",
    "    val_files = file_list[train_end:val_end]\n",
    "    check_files = file_list[val_end:]\n",
    "    \n",
    "    return train_files, val_files, check_files\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def copy_files(file_list, src_directory, dest_directory):\n",
    "    os.makedirs(dest_directory, exist_ok=True)\n",
    "    for file in file_list:\n",
    "        src_path = os.path.join(src_directory, file)\n",
    "        dest_path = os.path.join(dest_directory, file)\n",
    "        shutil.copy(src_path, dest_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Splitting and copying completed.\n"
     ]
    }
   ],
   "source": [
    "# Iterate over each class in the mapping\n",
    "for base_class, target_class in class_mapping.items():\n",
    "    src_class_dir = os.path.join(base_directory, base_class)\n",
    "    train_target_dir = os.path.join(target_directory, 'train', target_class)\n",
    "    val_target_dir = os.path.join(target_directory, 'val', target_class)\n",
    "    check_target_dir = os.path.join(target_directory, 'check', target_class)\n",
    "    \n",
    "    # Get the list of files in the source directory\n",
    "    files = [f for f in os.listdir(src_class_dir) if os.path.isfile(os.path.join(src_class_dir, f))]\n",
    "    \n",
    "    # Downsample the Grocery class to 2500 images\n",
    "    #if base_class == 'gro_processed':\n",
    "    #    files = downsample_class(files, 2500)\n",
    "    \n",
    "    # Split the dataset\n",
    "    train_files, val_files, check_files = split_dataset(files)\n",
    "    \n",
    "    # Copy the files to the target directories\n",
    "    copy_files(train_files, src_class_dir, train_target_dir)\n",
    "    copy_files(val_files, src_class_dir, val_target_dir)\n",
    "    copy_files(check_files, src_class_dir, check_target_dir)\n",
    "\n",
    "print(\"Splitting and copying completed.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of files with incorrect extension: 0\n",
      "Number of images with incorrect size: 0\n",
      "Number of images with incorrect channels: 0\n",
      "Number of files with incorrect extension: 0\n",
      "Number of images with incorrect size: 0\n",
      "Number of images with incorrect channels: 0\n",
      "Number of files with incorrect extension: 0\n",
      "Number of images with incorrect size: 0\n",
      "Number of images with incorrect channels: 0\n",
      "                            Class  Train  Validation  Check  Total\n",
      "0                     ELECTRONICS   1353         351     54   1758\n",
      "1                    PET_SUPPLIES   1260         327     50   1637\n",
      "2           HOBBY_ARTS_STATIONERY   1091         283     43   1417\n",
      "3              HOME_KITCHEN_TOOLS   1715         445     68   2228\n",
      "4                         GROCERY   3978        1033    156   5167\n",
      "5                  SPORTS_OUTDOOR   1235         321     49   1605\n",
      "6                   BEAUTY_HEALTH   1202         312     48   1562\n",
      "7  CLOTHING_ACCESSORIES_JEWELLERY   1071         278     42   1391\n",
      "8                   BABY_PRODUCTS   1087         282     43   1412\n"
     ]
    }
   ],
   "source": [
    "# Check all files: is there anything apart from jpeg file\n",
    "# is there anything not 224*224*3\n",
    "# show class distributions\n",
    "\n",
    "import os\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "\n",
    "def count_images_in_directory(directory):\n",
    "    counts = {}\n",
    "    incorrect_extension_count = 0\n",
    "    incorrect_size_count = 0\n",
    "    incorrect_channels_count = 0\n",
    "\n",
    "    for class_name in os.listdir(directory):\n",
    "        class_dir = os.path.join(directory, class_name)\n",
    "        if os.path.isdir(class_dir):\n",
    "            valid_files = []\n",
    "            for file in os.listdir(class_dir):\n",
    "                file_path = os.path.join(class_dir, file)\n",
    "                if os.path.isfile(file_path):\n",
    "                    if not file.lower().endswith('.jpeg'):\n",
    "                        incorrect_extension_count += 1\n",
    "                    else:\n",
    "                        try:\n",
    "                            with Image.open(file_path) as img:\n",
    "                                if img.size != (224, 224):\n",
    "                                    incorrect_size_count += 1\n",
    "                                elif img.mode != 'RGB':\n",
    "                                    incorrect_channels_count += 1\n",
    "                                else:\n",
    "                                    valid_files.append(file)\n",
    "                        except Exception as e:\n",
    "                            print(f\"Error processing file {file_path}: {e}\")\n",
    "            \n",
    "            counts[class_name] = len(valid_files)\n",
    "    \n",
    "    print(f\"Number of files with incorrect extension: {incorrect_extension_count}\")\n",
    "    print(f\"Number of images with incorrect size: {incorrect_size_count}\")\n",
    "    print(f\"Number of images with incorrect channels: {incorrect_channels_count}\")\n",
    "\n",
    "    return counts\n",
    "\n",
    "def create_counts_dataframe(train_counts, val_counts, check_counts):\n",
    "    data = {\n",
    "        'Class': [],\n",
    "        'Train': [],\n",
    "        'Validation': [],\n",
    "        'Check': []\n",
    "    }\n",
    "    \n",
    "    all_classes = set(train_counts.keys()).union(set(val_counts.keys())).union(set(check_counts.keys()))\n",
    "    \n",
    "    for class_name in all_classes:\n",
    "        data['Class'].append(class_name)\n",
    "        data['Train'].append(train_counts.get(class_name, 0))\n",
    "        data['Validation'].append(val_counts.get(class_name, 0))\n",
    "        data['Check'].append(check_counts.get(class_name, 0))\n",
    "    \n",
    "    df = pd.DataFrame(data)\n",
    "    return df\n",
    "\n",
    "# Directories for train, val, and check\n",
    "train_dir = os.path.join(target_directory, 'train')\n",
    "val_dir = os.path.join(target_directory, 'val')\n",
    "check_dir = os.path.join(target_directory, 'check')\n",
    "\n",
    "# Count images in each directory\n",
    "train_counts = count_images_in_directory(train_dir)\n",
    "val_counts = count_images_in_directory(val_dir)\n",
    "check_counts = count_images_in_directory(check_dir)\n",
    "\n",
    "# Create a DataFrame with the counts\n",
    "df_counts = create_counts_dataframe(train_counts, val_counts, check_counts)\n",
    "df_counts['Total'] = df_counts['Train'] + df_counts['Validation'] + df_counts['Check']\n",
    "\n",
    "print(df_counts)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "18177"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_counts['Total'].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
